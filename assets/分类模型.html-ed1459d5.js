import{_ as p,Q as o,S as e,a5 as _}from"./framework-ec2af7a3.js";const n={},r=_('<h1 id="分类模型" tabindex="-1"><a class="header-anchor" href="#分类模型" aria-hidden="true">#</a> 分类模型</h1><p>基本概念</p><p><strong>信息熵：</strong></p><p>信息熵用来衡量事件的不确定性的大小，计算公式如下： $Infor(x)=−p(x)×log_2p(x) $ 信息熵具有可加性，即多个期望信息，计算公式如下： $Infor(X)=−∑_i=1^m p(x_i)×log_2p(x_i)$</p><p><strong>信息增益：</strong> 信息增益表示某一特征的信息对类标签的不确定性减少的程度。 $g(D│A)=Infor(D)−Infor(D|A)$ 其中Infor(D|A)是在特征A给定条件下对数据集合D进行划分所需要的期望信息，它的值越小表示分区的纯度越高，计算公式如下所示。 $Infor(D|A)=∑_j=1^n |D_j|/|D|×Info(D_j)$ 其中n是数据分区数，|D_j|表示第j个数据分区的长度，|D_j|/|D|表示第j个数据分区的权重。</p><blockquote><p>回归分为解释型回归与预测型回归</p></blockquote><p>通过数据判断类型，分类二分类和多分类</p><p>使用逻辑回归：</p><ul><li><p>线性概率模型（LPM）</p></li><li><p>两点分布</p></li><li><p>非线性模型，可以使用极大似然估计法（MLE）进行估计</p></li></ul><p>预测型回归，加入平方项后可能会出现过拟合现象，这是对于样本数据的预测会非常好，但是对于样本外的数据的预测效果可能会很差（与龙格现象有点相似）</p><p>如何确定合适的模型：把数据分为「训练组」和「测试组」，用训练组的数据来估计出模型，再用测试组的数据来进行测试（一般比例是 8 : 2）</p><p>Fisher 线性判别分析：</p><p>该方法的思想：给定训练集样例，设法将样例投影到一维的直线上，使得同样样例的投影点尽可能接近和密集，异类投影点尽可能远离</p><p>核心问题就是：找到线性向量</p>',14),t=[r];function i(l,s){return o(),e("div",null,t)}const c=p(n,[["render",i],["__file","分类模型.html.vue"]]);export{c as default};
